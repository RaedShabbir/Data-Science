{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wget http://pjreddie.com/media/files/cifar.tgz    \n",
    "**Important:** Before proceeding, the student must reorganize the downloaded dataset files to match the expected directory structure, so that there is a dedicated folder for each class under 'test' and 'train', e.g.:\n",
    "\n",
    "```\n",
    "* test/airplane/airplane-1001.png\n",
    "* test/bird/bird-1043.png\n",
    "\n",
    "* train/bird/bird-10018.png\n",
    "* train/automobile/automobile-10000.png\n",
    "```\n",
    "\n",
    "\n",
    "Only run below code if cifar hasnt been organized \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "folders = [\"data/cifar/train/\", \"data/cifar/test/\"]\n",
    "\n",
    "#for each label save all files with that label name to a new subfolder\n",
    "#prints number of files in each new subfolder as a sanity check \n",
    "#5000 for each in training, 1000 for testing \n",
    "for folder in folders:    \n",
    "    for label in labels:\n",
    "        print (label)\n",
    "        os.makedirs(folder+label)\n",
    "        files = !ls {folder}\n",
    "        file_counter = 0\n",
    "        for filename in files:\n",
    "            if label in filename and \".png\" in filename:\n",
    "                file_counter += 1\n",
    "                src = folder+filename\n",
    "                dst = folder+label+\"/\"+filename\n",
    "                shutil.move(src, dst)\n",
    "        print(file_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load and Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt\n",
      "models\n",
      "test\n",
      "tmp\n",
      "train\n",
      "airplane\n",
      "automobile\n",
      "bird\n",
      "cat\n",
      "deer\n",
      "dog\n",
      "frog\n",
      "horse\n",
      "ship\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "from fastai.conv_learner import *\n",
    "\n",
    "PATH = \"data/cifar/\"\n",
    "os.makedirs(PATH, exist_ok =True) #makes dirs if they dont \n",
    "\n",
    "!ls {PATH}\n",
    "\n",
    "if not os.path.exists(f\"{PATH}/train/bird\"):\n",
    "   raise Exception(\"expecting class subdirs under 'train/' and 'test/'\")\n",
    "!ls {PATH}/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#pass in mean and std of each channel for both training and testing \n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), \n",
    "         np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "def get_data(sz, bs):\n",
    "    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8)\n",
    "    return ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(64,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 samples, 3 channels, 64 by 64\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x211b3b6a9b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.trn_ds.denorm(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "lr = 1e-2\n",
    "data = get_data(32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet (nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #transform x to be correct size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for l in self.layers:\n",
    "            l_x = l(x)\n",
    "            x = F.relu(l_x)\n",
    "        return F.log_softmax(l_x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create learn object from a custom pytorch model and model data object \n",
    "learn = ConvLearner.from_model_data(FCNet([32*32*3,40,10]), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=3072, out_features=40, bias=True)\n",
       "    (1): Linear(in_features=40, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[122880, 40, 400, 10]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.numel() for o in learn.model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Linear-1',\n",
       "              OrderedDict([('input_shape', [-1, 3072]),\n",
       "                           ('output_shape', [-1, 40]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 122920)])),\n",
       "             ('Linear-2',\n",
       "              OrderedDict([('input_shape', [-1, 40]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 410)]))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7bd7d869c641fda873bb32d18e65b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 32/196 [01:32<07:52,  2.88s/it, loss=2.32] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-02ca863ce486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\FastAI Practise\\fastai\\learner.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, wds, linear, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLR_Finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\FastAI Practise\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[1;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\FastAI Practise\\fastai\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall_val\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIterBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Raed\\Anaconda3\\envs\\fastai\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    929\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\FastAI Practise\\fastai\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;31m# avoid py3.6 issue where queue is infinite and can result in memory exhaustion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Raed\\Anaconda3\\envs\\fastai\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Raed\\Anaconda3\\envs\\fastai\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Raed\\Anaconda3\\envs\\fastai\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 2)\n",
    "%time learn.fit(lr, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet (nn.Module):\n",
    "    def __init__ (self, layers, c):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(layers[i], layers[i+1],kernel_size=3, stride=2) \n",
    "            for i in range(len(layers)-1)])\n",
    "        self. pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward (self, x):\n",
    "        for l in self.layers:\n",
    "            x = F.relu(l(x)) #computers the conv for loop\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet([3,20,40,80], 10), data)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(end_lr=100)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-1, 2)\n",
    "%time learn.fit(1e-1, 4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Conv Net (add in Conv2D layer class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer and net definition are same in pytorch\n",
    "class ConvLayer (nn.Module):\n",
    "    def __init__(self, ni, nf):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet2 (nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x) #relu taken care of by layer class above\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet2([3, 20, 40, 80], 10), data)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-1, 2)\n",
    "%time learn.fit(1e-1, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Norm \n",
    "Adding in batch norm stabilizes convergence and weight matrices by keeping them at reasonable scale through normalizing on each layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=kernel_size, stride=stride, \n",
    "                             bias=False,padding=1)\n",
    "        self.a = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.m = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        #x_chan repersents the channel values for each sample\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1) \n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds =  x_chan.std(1)[:,None,None]\n",
    "        return (x-self.means)/ self.stds * self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.6555 -1.1018 -0.7108  ...   0.9842  0.6417 -1.0652\n",
      " 2.0097  1.4551 -0.3500  ...  -0.1573 -0.0112  0.4167\n",
      " 0.2730  0.5392 -0.8584  ...   0.0482 -0.4714  1.2618\n",
      "          ...             ⋱             ...          \n",
      "-1.1181  1.1319  2.3021  ...   0.1011 -0.1044 -0.5180\n",
      " 0.3100 -1.3992 -0.3047  ...   1.0966 -0.5785  0.0566\n",
      " 0.9891  0.2972  0.1819  ...  -0.0825 -1.5031 -0.0631\n",
      "[torch.FloatTensor of size 20x60]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,20,20)\n",
    "a_chan = a.transpose(0,1).contiguous().view(a.size(1),-1)\n",
    "print(a_chan)\n",
    "\n",
    "mean = a_chan.mean(1)[:,None,None]\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,10,kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([\n",
    "            BNLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
    "        ])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #first layer is conv with large filter to capture rich features \n",
    "        x = self.conv1(x)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 10, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 760)])),\n",
       "             ('Conv2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 10, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1800)])),\n",
       "             ('BNLayer-3',\n",
       "              OrderedDict([('input_shape', [-1, 10, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 7200)])),\n",
       "             ('BNLayer-5',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 28800)])),\n",
       "             ('BNLayer-7',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 115200)])),\n",
       "             ('BNLayer-9',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-10',\n",
       "              OrderedDict([('input_shape', [-1, 160]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1610)]))])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = ConvLearner.from_model_data(ConvBNNet([10, 20, 40, 80, 160], 10), data)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ba52ae5814a869c186f2e83da571c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.161058   1.071944   0.621     \n",
      "    1      1.095507   1.061649   0.6219                     \n",
      "Wall time: 28.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.06165]), 0.6219]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(3e-2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2799ef1d370a474195b7b13018de07e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.04591    0.951704   0.6654    \n",
      "    1      0.997957   0.923001   0.6748                      \n",
      "    2      0.95889    0.898968   0.6835                      \n",
      "    3      0.922772   0.861733   0.6991                      \n",
      "Wall time: 57.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.86173]), 0.6991]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep BatchNorm\n",
    "\n",
    "We now add another stride 1 layer after each stride 2 layer, note that stride 2 layers halve the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNNet2(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([BNLayer(layers[i], layers[i+1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([BNLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #first layer is conv with large filter to capture rich features \n",
    "        x = self.conv1(x)\n",
    "        for l, l2 in zip(self.layers, self.layers2):\n",
    "            x = l(x)\n",
    "            x = l2(x)\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c74492dc3904bb79813d37d9117c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.517748   1.346363   0.512     \n",
      "    1      1.285908   1.198571   0.5691                     \n",
      "Wall time: 33.4 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279dd77761f142578111fcc1d896d66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.105306   1.020558   0.6302    \n",
      "    1      1.038023   0.987595   0.6551                     \n",
      "Wall time: 32.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.98759]), 0.6551]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = ConvLearner.from_model_data(ConvBNNet2([10, 20, 40, 80, 160], 10), data)\n",
    "%time learn.fit(1e-2, 2)\n",
    "%time learn.fit(1e-2, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayer(BNLayer):\n",
    "    def forward(self,x):\n",
    "        return x + super().forward(x)  \n",
    "    \n",
    "class Resnet (nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([\n",
    "            BNLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
    "        ])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l, l2, l3 in zip(self.layers, self.layers2, self.layers3):\n",
    "            x = l3(l2(l(x)))\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a03470bc4904eba8b1f5f7881d68287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.632872   1.653201   0.4711    \n",
      "    1      1.377909   1.245565   0.5487                     \n",
      "Wall time: 39.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.24556]), 0.5487]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = ConvLearner.from_model_data(Resnet([10, 20, 40, 80, 160], 10), data)\n",
    "wd=1e-5\n",
    "%time learn.fit(1e-2, 2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4a4f354b174fc099171f8f4e2941e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.172699   1.127429   0.5946    \n",
      "    1      1.124879   1.063845   0.6252                     \n",
      "    2      0.984406   0.949687   0.668                       \n",
      "    3      1.033848   0.988644   0.6471                     \n",
      "    4      0.912622   0.959641   0.6712                      \n",
      "    5      0.823088   0.838152   0.7074                      \n",
      "    6      0.771403   0.806605   0.7183                      \n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c9ca7925084275b2cd6aa1fec6d0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.885609   0.911275   0.6819    \n",
      "    1      0.785193   0.838535   0.7125                      \n",
      "    2      0.700643   0.733968   0.7387                      \n",
      "    3      0.667494   0.725259   0.7405                      \n",
      "    4      0.775057   0.765866   0.7364                      \n",
      "    5      0.690376   0.726724   0.7475                      \n",
      "    6      0.609008   0.66837    0.7645                      \n",
      "    7      0.577054   0.665488   0.7691                      \n",
      "    8      0.680076   0.734451   0.7457                      \n",
      "    9      0.620363   0.679057   0.7674                      \n",
      "    10     0.553914   0.626078   0.7818                      \n",
      "    11     0.513744   0.631943   0.7812                      \n",
      "    12     0.627038   0.671287   0.7671                      \n",
      "    13     0.560127   0.617067   0.788                       \n",
      "    14     0.488473   0.597277   0.7923                      \n",
      "    15     0.454483   0.601125   0.7917                      \n",
      "    16     0.556855   0.655555   0.7773                      \n",
      "    17     0.512136   0.600403   0.7953                      \n",
      "    18     0.451938   0.589473   0.8035                      \n",
      "    19     0.418301   0.564322   0.8072                      \n",
      "    20     0.531619   0.630356   0.7861                      \n",
      "    21     0.471122   0.57931    0.8046                      \n",
      "    22     0.419221   0.549659   0.8137                      \n",
      "    23     0.371604   0.544313   0.817                       \n",
      "    24     0.486894   0.580014   0.8055                      \n",
      "    25     0.44068    0.578245   0.8111                      \n",
      "    26     0.385043   0.580075   0.8109                      \n",
      "    27     0.357598   0.542311   0.8181                      \n",
      "    28     0.467916   0.600018   0.8015                      \n",
      "    29     0.406974   0.561983   0.8105                      \n",
      "    30     0.355695   0.544935   0.82                        \n",
      "    31     0.322325   0.529711   0.8272                      \n",
      "Wall time: 10min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.52971]), 0.8272]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2, wds=wd)\n",
    "%time learn.fit(1e-2, 8, cycle_len=4, wds=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 2\n",
    "\n",
    "Increased feature sizes and added dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet2 (nn.Module):\n",
    "    def __init__(self, layers, c, p=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = BNLayer(3, 16, stride=1, kernel_size=7)\n",
    "        self.layers = nn.ModuleList([\n",
    "            BNLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
    "        ])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l, l2, l3 in zip(self.layers, self.layers2, self.layers3):\n",
    "            x = l3(l2(l(x)))\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.drop(x)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d21e61e44cf4e1787631d6ec8d62083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.655834   1.518325   0.4389    \n",
      "    1      1.462612   1.312996   0.5295                     \n",
      "Wall time: 44.8 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad322544da094dee98f0694561ebc964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.231459   1.131251   0.595     \n",
      "    1      1.18313    1.075431   0.6152                     \n",
      "    2      1.054282   1.028196   0.6275                     \n",
      "    3      1.124273   1.102465   0.609                      \n",
      "    4      1.005835   0.939598   0.6679                     \n",
      "    5      0.899107   0.883041   0.6857                      \n",
      "    6      0.851606   0.861324   0.6934                      \n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a376a94ca94c998cc4dddaaea339a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.974136   0.901752   0.6831    \n",
      "    1      0.879838   0.825353   0.7102                      \n",
      "    2      0.78337    0.77476    0.7293                      \n",
      "    3      0.73282    0.747417   0.7365                      \n",
      "    4      0.850769   0.82712    0.7095                      \n",
      "    5      0.765538   0.742317   0.741                       \n",
      "    6      0.688831   0.698891   0.7583                      \n",
      "    7      0.63725    0.672479   0.7649                      \n",
      "    8      0.752892   0.726968   0.745                       \n",
      "    9      0.681857   0.684996   0.7632                      \n",
      "    10     0.603353   0.642885   0.7742                      \n",
      "    11     0.553919   0.63652    0.7761                      \n",
      "    12     0.683906   0.718445   0.7523                      \n",
      "    13     0.618704   0.624284   0.7833                      \n",
      "    14     0.545724   0.604186   0.7912                      \n",
      "    15     0.521278   0.597375   0.7982                      \n",
      "    16     0.618571   0.668534   0.7747                      \n",
      "    17     0.564809   0.687227   0.7722                      \n",
      "    18     0.500251   0.58839    0.8003                      \n",
      "    19     0.461529   0.55711    0.8093                      \n",
      "    20     0.587995   0.625317   0.7856                      \n",
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.from_model_data(Resnet2([16, 32, 64, 128, 256], 10, 0.2), data)\n",
    "wd=1e-6\n",
    "%time learn.fit(1e-2, 2, wds=wd)\n",
    "%time learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2, wds=wd)\n",
    "%time learn.fit(1e-2, 8, cycle_len=4, wds=wd)\n",
    "log_preds,y = learn.TTA()\n",
    "preds = np.mean(np.exp(log_preds),0)\n",
    "metrics.log_loss(y,preds), accuracy(preds,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
